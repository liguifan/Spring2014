package Adaboosting;

import java.io.BufferedReader;
import java.io.File;
import java.io.FileReader;
import java.io.IOException;
import java.util.ArrayList;

import datastructure.Tuple;

public class adaboosting {

	public static void main(String[] args) {
		// TODO Auto-generated method stub
		
		
		File file=new File("/Users/liguifan/Desktop/data/rcv1-train.vw");
		BufferedReader reader=null;
	
		ArrayList<ArrayList<Tuple>> alldata=new ArrayList<ArrayList<Tuple>>();

		try{
			reader=new BufferedReader(new FileReader(file));
			String tempstr=null;
			
			while((tempstr=reader.readLine())!=null){
				ArrayList<Tuple> path=read_into_tuples(tempstr);
				alldata.add(path);
			}
			
		}catch (IOException e){
				e.printStackTrace();
			}finally{
				if(reader!=null){
					try{
						reader.close();
					}catch (IOException e1){
					}
				}
			}
		
		
		
		
		
		
	}
	
static double learning_rate_with_importance(double h, ArrayList<Tuple> x_list, int y, double[] theta,double learning_rate){
	
	double A=norm_square_sparse(x_list);
	System.out.println("norm x is : "+A);
	double B=sparse_dot_product(theta, x_list);
	System.out.println("sparse dot product is : "+B);
	double s=(B-y)/A*(1-Math.exp(-h*learning_rate*A));
	
	return s;
}
	

public final static double sparse_dot_product(double[] weight, ArrayList<Tuple> tuple){
	
	double sum=0;
	for(Tuple x:tuple){
		sum+=weight[x.index]*x.value;
	}
	return sum;
}


// Test OK!
public static double norm_square_sparse(ArrayList<Tuple> x_list){
	
	double sum=0;
	for(Tuple x:x_list){
		sum+=x.value*x.value;
	}
	return sum;
}



}
