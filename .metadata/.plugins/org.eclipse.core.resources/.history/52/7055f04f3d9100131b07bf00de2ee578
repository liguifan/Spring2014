package Stochastic_gradient_decent;

import java.io.BufferedReader;
import java.io.BufferedWriter;
import java.io.File;
import java.io.FileReader;
import java.io.FileWriter;
import java.io.IOException;
import java.util.ArrayList;
import java.util.Random;
import java.util.concurrent.CountDownLatch;

import datastructure.Tuple;

public class gradient_decent {
	
	public static void main(String[] args) {
		File file=new File("/Users/liguifan/Desktop/data/rcv1-test.vw");
		BufferedReader reader=null;
		final int SAMPLE_SIZE=4000;
		final int MAX_ITER=8000;
		final double learning_rate=0.1;
		final int len=50000;

		int counter=0;
		int n=0;
		double[] theta=new double[len];
		long p_start=System.currentTimeMillis();
		ArrayList<ArrayList<Tuple>> alldata=new ArrayList<ArrayList<Tuple>>();
		ArrayList<Integer> y_set=new ArrayList<Integer>();
		Random rand=new Random();
		try{
			reader=new BufferedReader(new FileReader(file));
			String tempstr=null;
			
			while((tempstr=reader.readLine())!=null){
				ArrayList<Tuple> path=read_into_tuples(tempstr);
				alldata.add(path);
				int y_original=(int) tempstr.charAt(0)-48;
				int y_after=(y_original)>0?1:-1;
				y_set.add(y_after);
				counter++;
				// Every 40000 data example, we permutate the data set and train theta on them.
				if(counter%SAMPLE_SIZE==0){
					for(int i=0;i<=MAX_ITER;i++){
						//n is the random number between 0 and 40000;
						n=rand.nextInt(SAMPLE_SIZE);
					    theta=update_theta_logistic_loss(theta,learning_rate,y_set.get(n),alldata.get(n));
					}
					alldata.clear();
					y_set.clear();	
				}
			}
			reader.close();
		}
		catch (IOException e){
			e.printStackTrace();
		}finally{
			if(reader!=null){
				try{
					reader.close();
				}catch (IOException e1){
				}
			}
		}
		
		long p_end=System.currentTimeMillis();

		for(int j = 0; j < theta.length; j++) {
		    try{ 
		    	BufferedWriter bw = new BufferedWriter(new FileWriter("/Users/liguifan/Desktop/data/theta_logistic.txt", true));
		        String s;
		        s =Double.toString(theta[j]);
		        bw.write(s);
		        bw.write(" ");
		        bw.flush();
		    } catch(IOException ex) {}  
		}
	}

	//path = alldata.get(i) y=y_set.get(i);
	public static double[] update_theta_square_loss(double[] theta,double learning_rate,int y, ArrayList<Tuple> path){
		double diff=y-sparse_dot_product(theta, path);
		for(Tuple x:path){
			theta[x.index]+=learning_rate*diff*x.value;
		}
		return theta;
	}
	
	
	public static double[] update_theta_logistic_loss(double[] theta,double learning_rate,int y, ArrayList<Tuple> path){
		double term=y*sparse_dot_product(theta, path);
		for(Tuple x:path){
			//why the sign is +?
			theta[x.index]+=y*(Math.exp(-term)/(1+Math.exp(-term)))*x.value;
//			System.out.println(theta[x.index]);
		}
		return theta;
	}
	
	
	public final static double sparse_dot_product(double[] weight, ArrayList<Tuple> tuple){
		double sum=0;
		for(Tuple x:tuple){
			sum+=weight[x.index]*x.value;
		}
		return sum;
	}
	
	
	public static double h_theta(double[] theta, ArrayList<Tuple> X){
		double sum=0;
		for(Tuple x:X){
			sum+=theta[x.index]*x.value;
		}
		return sum;
	}
	
	public final static ArrayList<Tuple> read_into_tuples(String line){
		/*
		String[] line1=line.split("features");
		String[] line2=line1[1].split("const:");
		String valid_line=line2[0].substring(1,line2[0].length());
		*/
		String valid_line=line.substring(12,line.length()-10);
		String[] arr=valid_line.split(" ");
		ArrayList<Tuple> set=new ArrayList<Tuple>();
		for(String single:arr){
			Tuple temp=extract_value(single);
			set.add(temp);
		}
		return set;
	}
	
	// test ok!
	// Extract every single term of that line;
	public final static Tuple extract_value(String single){
		String new_str=single.substring(1,single.length());
		String[] arr=new_str.split(":");
//		int index=parseInt(arr[0]);
		int index=parseInt(arr[0]);
		double value=Double.parseDouble(arr[1]);
		return new Tuple(index,value);
		
	}
	
	public static int parseInt(String str){
		int sum=0;
		for(int i=0;i<=str.length()-1;i++){
			sum=10*sum+((int)str.charAt(i)-48);
		}
		return sum;
	} 
}
